# SLAVA: Benchmark of Sociopolitical Landscape and Value Analysis

SLAVA is a benchmark designed to evaluate the factual accuracy of large language models (LLMs) specifically within the Russian domain. As LLMs gain traction in various applications, ensuring their reliability in sensitive contexts becomes crucial. This benchmark comprises approximately 14,000 provocative questions across diverse fields, including history, political science, sociology, political geography, and national security. Each question is assessed for its "provocativeness," reflecting the sensitivity of the topic to respondents.

Our scientific article about the [SLAVA](extensions/SLAVA.pdf?)

## Testing models on our open data

